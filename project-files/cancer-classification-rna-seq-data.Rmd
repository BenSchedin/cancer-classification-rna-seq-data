---
title: "Cancer Classification With RNA-Seq Data"
author: "B. D. Schedin"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    df_print: paged
    toc: yes
    toc_float: yes
    toc_depth: 3
    theme: yeti
    highlight: pygments
    fig_caption: yes
fontsize: 11pt
---

```{r setup, include=FALSE}

# Global chunk options
knitr::opts_chunk$set(echo = TRUE)

# Project paths
projRoot <- "C:/_git_/cancer-classification-rna-seq-data/"

# Project libraries
library(tidyverse)
library(e1071)
library(class)
library(ggdendro)
library(neuralnet)
library(ggcorrplot)
library(MASS)
library(randomForest)

# Sourced files
source(paste0(projRoot, "r-code/functions/neural-net.R"))
source(paste0(projRoot, "r-code/functions/diag-accuracy.R"))

```

# 1. Abstract





# 2. Introduction
### Data Set

### Goal

### Existing Methods in Research

### Findings


# 3. Methods and Results
### Data Preprocessing

### Dimension Reduction

### Model Selection

### Results




# 4. Limitations
try different cost and gamma parameters for svm tune
try linear and radial svm kernels
add k-fold cv to nn implementation
remove ci from knn 1:100 visual
add accuracy assessment to hclust
update hclust plots
replace source files with github source compared to local source
double check and add model assumption analysis to lda/qda




# 5. Conclusion





# 6. Appendix

## Preprocessing
The initial step in this analysis was to load the data into R and prepare it for use during the rest of the analysis. This preprocessing step included cleaning up unneeded columns, checking the data for missing values, removing genes which appear to be inactive (defined as genes with $expression = 0$ for $> 25\%$ of the available samples), and standardizing the features with the `scale` function. The scaling would prove to be unnecessary, as PCA was applied to the data for dimension reduction which includes scaling; however, the data was still scaled in case ad-hoc processing of the original data was desired.
```{r preprocessing, eval=FALSE}

# Loading raw data
rawData <- read.csv(paste0(projRoot, "data/raw/data.csv"))
rawLabels <- read.csv(paste0(projRoot, "data/raw/labels.csv"))

# Setting sample IDs to row names, removing sample ID columns
data <- rawData
rownames(data) <- rawData$X
data <- data %>% dplyr::select(-X)

labels <- rawLabels
rownames(labels) <- rawLabels$X
labels <- labels %>% dplyr::select(-X)

# Checking for missing values
missing <- sapply(data, function(x) sum(is.na(x)))
cat("Found", length(missing[missing > 0]), "columns with missing values.\n")

# Removing genes which are not expressed for more than 25% of samples
preCounts <- map_int(data, function(x) sum(x == 0))
data <- data[colMeans(data == 0) <= 0.25]
postCounts <- map_int(data, function(x) sum(x == 0))

cat("Removed", length(preCounts) - length(postCounts), "columns containing genes unexpressed in more than 25% of samples.\n")

# Scaling features
data <- scale(data)

# Exporting preprocessed data to file
save("data", "labels", file=paste0(projRoot, "data/processed/rna-seq-preprocessed"))

```
In total: No columns were found to have missing values, and 3,790 genes were removed from the data set. This preprocessed data was then saved to disk using the built-in `save` function for later use and quicker load times on supsequent loads.


## Principal Component Analysis
```{r pca}

# Setting chunk seed
set.seed(123)

# Loading preprocessed data
load(paste0(projRoot, "data/processed/rna-seq-preprocessed"))
data <- as.data.frame(data)

# PCA on all features
pca <- prcomp(data)

# Calculating cumulative variance for each principal component
cumVar <- cumsum((nrow(data) - 1) * ((pca$sdev)^2)/sum(data^2))
cumVarData <- data.frame(PC = 1:length(cumVar), CumulativeVariance = cumVar)

# Plotting the cumulative variance
ggplot(cumVarData, aes(x=PC, y=CumulativeVariance)) +
  geom_point() +
  geom_line() +
  theme_bw() +
  labs(title="Component Cumulative Variance", x="PC", y="Variance")
ggsave(paste0(projRoot, "figures/pca-cumulative-variance.png"), device="png", width=6, height=4)

# Visualizing the first two component scores
scores <- as.data.frame(pca$x[,1:2])
scores$Class <- labels$Class

ggplot(scores, aes(PC1, PC2, color=Class, shape=Class)) +
  geom_point() +
  geom_hline(yintercept=0, linetype="dotted") +
  geom_vline(xintercept=0, linetype="dotted") +
  theme_bw() +
  labs(title="Scores: PC1 and PC2", x="PC1 Scores", y="PC2 Scores")
ggsave(paste0(projRoot, "figures/pca-component-scores-plot.png"), device="png", width=6, height=4)

# Determining the number of components needed to reach 50% cumulative variance
cat("Number of components required to reach 50% cumulative variance:", length(cumVar[cumVar <= 0.50]), "\n")

# Extracting the first 8 principal components
pca8 <- as.data.frame(pca$x[, 1:8])

# Combining selected components and labels to create a "full" data set
full <- pca8
full$Class <- as.factor(labels$Class)

```

## K-Means Clustering 
```{r kmeans}

# Setting chunk seed
set.seed(123)

# Applying k-means to the data
k <- 5
kmeans <- kmeans(pca8, centers=k, iter.max=100, nstart=25, algorithm=c("Hartigan-Wong"))

# Visualizing the results
kmeansResults <- data.frame(pca8)
kmeansResults$Class <- as.factor(labels$Class)
kmeansResults$Cluster <- as.factor(kmeans$cluster)

ggplot(kmeansResults, aes(PC1, PC2)) +
  geom_point(aes(color=Class, shape=Cluster)) +
  theme_bw() +
  labs(title=paste0(k, "-Means Clustering", sep=""), x="PC1", y="PC2")
ggsave(paste0(projRoot, "figures/pca-kmeans.png"), device="png", width=6, height=4)

# Displaying the results
predTable <- table(kmeansResults$Class, kmeansResults$Cluster)
predTable

# Exporting results table to .csv file
predTable <- as.data.frame.matrix(predTable)
write.csv(predTable, file=paste0(projRoot, "tables/kmeans.csv"))

# Calculating "error" rate
dominant <- sapply(predTable, function(x) max(x))
total <- sapply(predTable, function(x) sum(x))

cat("Accuracy (based on dominant class samples per cluster): ", round(sum(dominant) / sum(total), 4) * 100, "% \n", sep="")

```

## Hierarchical Clustering
```{r hclust}

# Setting chunk seed
set.seed(123)

# Applying hierarchical clustering with multiple linkages
hcAverage <- hclust(dist(pca8), method="average")
hcSingle <- hclust(dist(pca8), method="single")
hcComplete <- hclust(dist(pca8), method="complete")

# Visualizing results with dendrograms
ggdendrogram(hcAverage, rotate=FALSE, size=2)
ggdendrogram(hcSingle, rotate=FALSE, size=2)
ggdendrogram(hcComplete, rotate=FALSE, size=2)

```

## K-Nearest Neighbors
```{r knn, warning=FALSE}

# Setting the seed for the chunk
set.seed(123)

# Splitting the data into training and test sets, 75-25 split
trainIndices <- sample(1:nrow(pca8), floor(0.75 * nrow(pca8)), replace=FALSE)
testIndices <- (1:nrow(pca8))[-trainIndices]

trainData <- as.data.frame(pca8[trainIndices, ])
trainLabels <- as.data.frame(labels[trainIndices, ])
colnames(trainLabels) <- "Class"

testData <- as.data.frame(pca8[testIndices, ])
testLabels <- as.data.frame(labels[testIndices, ])
colnames(testLabels) <- "Class"

# Implementing KNN for k=1:100
knnResults <- list()
knnAccuracies <- list()

for (i in 1:100)
{
  knnTemp <- knn(trainData, testData, cl=trainLabels$Class, k=i)
  predTableTemp <- table(knnTemp, testLabels[[1]])
  accuracy <- round(sum(diag(predTableTemp)) / nrow(testData), 4) * 100
  knnResults[[i]] <- predTableTemp
  knnAccuracies[[i]] <- accuracy
}

# Displaying best model results for k=1:100
knnAccuracies <- unlist(knnAccuracies)
bestAccuracy <- max(knnAccuracies)
bestIndex <- which(knnAccuracies == max(knnAccuracies))[1]
predTable <- knnResults[[bestIndex]]

cat("Best model accuracy was ", bestAccuracy, "% with k=", bestIndex, "\n", sep="")
predTable

# Plotting results for k=1:100
ggplot(data=NULL, aes(x=1:100, y=knnAccuracies)) +
  geom_smooth() +
  theme_bw() +
  labs(title="K-Nearest Neighbors, k=1:100", x="k", y="Accuracy")
ggsave(paste0(projRoot, "figures/knn-accuracies.png"), device="png", width=6, height=4)

# Exporting results table to .csv file
predTable <- as.data.frame.matrix(predTable)
write.csv(predTable, file=paste0(projRoot, "tables/knn.csv"))

```

Write about k value selection

## Support Vector Machines
```{r svm, warning=FALSE}

# Setting chunk seed
set.seed(123)

# Splitting data into training and test sets, 75-25 split
trainIndices <- sample(1:nrow(full), 0.75*nrow(full), replace=FALSE)

trainData <- full[trainIndices,]
testData <- full[-trainIndices,]

# Training model and tuning hyperparameters with e1071::tune
tuneRadialSVM <- tune(svm,
                      train.x=trainData[, 1:8],
                      train.y=trainData$Class,
                      kernel="radial",
                      type="C",
                      ranges=list(cost=c(0.01, 0.1, 1, 5, 10, 50),
                                  gamma=c(0.5, 1, 2, 3, 4)))
summary(tuneRadialSVM)

# Extracting best resulting model
bestRadialSVM <- tuneRadialSVM$best.model
summary(bestRadialSVM)

# Testing best model and displaying results
yPred <- predict(bestRadialSVM, testData[,1:8])

predTable <- table(predicted=yPred, truth=testData$Class)
predTable

# Calculating error rate
cat("SVM Accuracy: ", round(sum(diag(predTable)) / nrow(testData), 4) * 100, "%\n", sep="")

# Exporting results table to .csv file
predTable <- as.data.frame.matrix(predTable)
write.csv(predTable, file=paste0(projRoot, "tables/radial-svm.csv"))

```

## Linear Discriminant Analysis
```{r lda}

# Setting the chunk seed
set.seed(123)

# Splitting data into training and test sets with 75-25 split
trainIndices <- sample(1:nrow(full), floor(0.75*nrow(full)), replace=FALSE)

trainData <- full[trainIndices, ]
testData <- full[-trainIndices, ]

# Building QDA model
ldaTrain <- lda(Class ~ ., data=trainData)
ldaTest <- predict(ldaTrain, newdata=testData)

# Reporting test accuracy
testPred <- table(testData$Class, ldaTest$class)
testPred

cat("Test model accuracy: ", accuracyDiag(testPred), "%\n", sep="")

# Exporting test results to .csv file
testPred <- as.data.frame.matrix(testPred)
write.csv(testPred, file=paste0(projRoot, "tables/lda-test.csv"))

```

## Quadratic Discriminant Analysis
```{r qda}

# Setting chunk seed
set.seed(123)

# Checking correlations between components
compCor <- cor(pca8)

ggcorrplot(compCor) + 
  theme(axis.text.x = element_text(size=11, angle=90, hjust=0.99, vjust=0.3), axis.text.y=element_text(size=11)) + 
  labs(title = "Component Correlations", x="Variable 1", y="Variable 2")
ggsave(paste0(projRoot, "figures/comp-correlations.png"), device="png", width=6, height=4)

# Checking for GMM violations
gmmData <- reshape2::melt(full, id="Class")

ggplot(gmmData, aes(x=value, fill=Class)) +
  geom_density(alpha=0.25) +
  theme_bw() +
  labs(title="Class Distributions", x="Value", y="Density")
ggsave(paste0(projRoot, "figures/comp-class-distributions.png"), device="png", width=6, height=4)

# Splitting data into training and test sets with 75-25 split
trainIndices <- sample(1:nrow(full), floor(0.75*nrow(full)), replace=FALSE)

trainData <- full[trainIndices, ]
testData <- full[-trainIndices, ]

# Building QDA model
qdaTrain <- qda(Class ~ ., data=trainData)
qdaTest <- predict(qdaTrain, newdata=testData)

# Reporting test accuracy
testPred <- table(testData$Class, qdaTest$class)
testPred

cat("Test model accuracy: ", accuracyDiag(testPred), "%\n", sep="")

# Exporting test results to .csv file
testPred <- as.data.frame.matrix(testPred)
write.csv(testPred, file=paste0(projRoot, "tables/qda-test.csv"))

```

## Neural Network
```{r nn}

# Setting chunk seed
set.seed(123)

# Splitting data into train and test sets, 75-25 split
trainIndices <- sample(1:nrow(full), nrow(full)*0.75, replace=FALSE)

trainData <- full[trainIndices,]
testData <- full[-trainIndices,]

# Fitting the model
nnet <- neuralnet(Class ~ ., trainData, hidden=c(10, 12), act.fct="logistic", linear.output=FALSE)

# Displaying the model
plot(nnet, show.weights=FALSE, information=TRUE, intercept=FALSE, rep="best", col.hidden="blue")

# Checking train set accuracy
trainPred <- nnPred(trainData, nnet)
trainPred

cat("Training model accuracy: ", accuracyDiag(trainPred), "%\n", sep="")

# Exporting train results table to .csv file
trainPred <- as.data.frame.matrix(trainPred)
write.csv(trainPred, file=paste0(projRoot, "tables/neural-net-train.csv"))

# Checking test set accuracy
testPred <- nnPred(testData, nnet)
testPred

cat("Test model accuracy: ", accuracyDiag(testPred), "%\n", sep="")

# Exporting test results table to .csv file
testPred <- as.data.frame.matrix(testPred)
write.csv(testPred, file=paste0(projRoot, "tables/neural-net-test.csv"))

```

## Random Forest
```{r randforest}

# Setting chunk seed
set.seed(123)

# Splitting the data into training and test sets, 75-25 split
trainIndices <- sample(1:nrow(full), 0.75*nrow(full), replace=FALSE)

trainData <- full[trainIndices, ]
testData <- full[-trainIndices, ]

# Building the model
rf <- randomForest(Class ~ ., data=trainData, ntree=100)
rfPred <- predict(rf, testData)

# Reporting test accuracy
testPred <- table(predicted=rfPred, truth=testData$Class)
testPred

cat("Test model accuracy: ", accuracyDiag(testPred), "%\n", sep="")

# Exporting classification table to file
testPred <- as.data.frame.matrix(testPred)
write.csv(testPred, file=paste0(projRoot, "tables/random-forest-results.csv"))

```

## Multinomial Logistic Regression
```{r mlr}

```










