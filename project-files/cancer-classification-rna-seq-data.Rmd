---
title: "Cancer Classification With RNA-Seq Data"
author: "B. D. Schedin"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
      toc: true
---

```{r setup, include=FALSE}

# Global chunk options
knitr::opts_chunk$set(echo = TRUE)

# Project paths
projRoot <- "C:/_git_/cancer-classification-rna-seq-data/"

# Project libraries
library(tidyverse)
library(e1071)
library(class)

```

# 1. Abstract





# 2. Introduction





# 3. Methods and Results





# 4. Criticisms of Methodology
try different cost and gamma parameters for svm tune
try linear and radial svm kernels
add k-fold cv to nn implementation





# 5. Conclusion





# 6. Appendix

## Dataset Information

## Preprocessing
```{r, eval=FALSE}

# Loading raw data
rawData <- read.csv(paste0(projRoot, "data/raw/data.csv"))
rawLabels <- read.csv(paste0(projRoot, "data/raw/labels.csv"))

# Setting sample IDs to row names, removing sample ID columns
data <- rawData
rownames(data) <- rawData$X
data <- data %>% select(-X)

labels <- rawLabels
rownames(labels) <- rawLabels$X
labels <- labels %>% select(-X)

# Checking for missing values
missing <- sapply(data, function(x) sum(is.na(x)))
cat("Found", length(missing[missing > 0]), "columns with missing values.\n")

# Removing genes which are not expressed for more than 25% of samples
preCounts <- map_int(data, function(x) sum(x == 0))
data <- data[colMeans(data == 0) <= 0.25]
postCounts <- map_int(data, function(x) sum(x == 0))

cat("Removed", length(preCounts) - length(postCounts), "columns containing genes unexpressed in more than 25% of samples.\n")

# Scaling features
data <- scale(data)

# Exporting preprocessed data to file
save("data", "labels", file=paste0(projRoot, "data/processed/rna-seq-preprocessed"))

```

## Principal Component Analysis
```{r}

# Setting chunk seed
set.seed(123)

# Loading preprocessed data
load(paste0(projRoot, "data/processed/rna-seq-preprocessed"))
data <- as.data.frame(data)

# PCA on all features
pca <- prcomp(data)
plot(pca, main="Scree Plot", xlab="PCs")

cumVar <- cumsum((nrow(data) - 1) * ((pca$sdev)^2)/sum(data^2))
cumVarData <- data.frame(PC = 1:length(cumVar), CumulativeVariance = cumVar)

ggplot(cumVarData, aes(x=PC, y=CumulativeVariance)) +
  geom_point() +
  geom_line() +
  theme_bw() +
  labs(title="Component Cumulative Variance", x="PC", y="Variance")
ggsave(paste0(projRoot, "figures/pca-cumulative-variance.png"), device="png", width=5, height=4)

# Number of features to reach 50% cumulative variance
cat("Number of components required to reach 50% cumulative variance:", length(cumVar[cumVar <= 0.50]), "\n")

# Extracting the first 8 principal components
pca8 <- as.data.frame(pca$x[, 1:8])

```

## K-Means Clustering 
```{r}

```

## Hierarchical Clustering
```{r}

```

## K-Nearest Neighbors
```{r}

# Setting the seed for the chunk
set.seed(123)

# Splitting th e data into training and test sets, 75-25 split
trainIndices <- sample(1:nrow(pca8), floor(0.75 * nrow(pca8)), replace=FALSE)
testIndices <- (1:nrow(pca8))[-trainIndices]

trainData <- as.data.frame(pca8[trainIndices, ])
trainLabels <- as.data.frame(labels[trainIndices, ])
colnames(trainLabels) <- "Class"

testData <- as.data.frame(pca8[testIndices, ])
testLabels <- as.data.frame(labels[testIndices, ])
colnames(testLabels) <- "Class"

# Implementing KNN
knn <- knn(trainData, testData, cl=trainLabels$Class, k=5)

# Reporting results
predTable <- table(knn, testLabels[[1]])
predTable

# Calculating error
round(sum(diag(predTable)) / nrow(testData), 2)

```

## Support Vector Machines
```{r}

# Setting chunk seed
set.seed(123)

# Preparing principal component data for use with SVM
svmData <- pca8
svmData$Class <- as.factor(labels$Class)

# Splitting data into training and test sets, 75-25 split
trainIndices <- sample(1:nrow(svmData), 0.75*nrow(svmData), replace=FALSE)

train <- svmData[trainIndices,]
test <- svmData[-trainIndices,]

# Training model and tuning hyperparameters with e1071::tune
tuneRadialSVM <- tune(svm,
                      train.x=train[, 1:8],
                      train.y=train$Class,
                      kernel="radial",
                      type="C",
                      ranges=list(cost=c(0.01, 0.1, 1, 5, 10, 50),
                                  gamma=c(0.5, 1, 2, 3, 4)))
summary(tuneRadialSVM)

# Extracting best resulting model
bestRadialSVM <- tuneRadialSVM$best.model
summary(bestRadialSVM)

# Testing best model and displaying results
yPred <- predict(bestRadialSVM, test[,1:8])

predTable <- table(predicted=yPred, truth=test$Class)
predTable

# Writing table to .csv for reporting
predTable <- as.data.frame.matrix(predTable)
write.csv(predTable, file=paste0(projRoot, "tables/radial-svm.csv"))

```

## Linear Discriminant Analysis
```{r}

```

## Quadratic Discriminant Analysis
```{r}

```

## Neural Network
```{r}

# Setting chunk seed
set.seed(123)

# Preparing principal component data for use with NN
nnData <- pca8
nnLabels <- labels

# Splitting data into train and test sets, 75-25 split
trainIndices <- sample(1:nrow(nnData), nrow(nnData), replace=FALSE)

trainData <- nnData[trainIndices,]
trainLabels <- as.data.frame(nnLabels[trainIndices,])
testData <- nnData[-trainIndices,]
testLabels <- nnLabels[-trainIndices,]

```













